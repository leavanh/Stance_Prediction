\chapter{Introduction}\label{intro}

Recent years have seen a rapid advancement in the field of Natural Language Processing (NLP), largely because of developments in neural networks, deep learning methods and availability of computing power. The ability of machines to accurately decipher and process human language, one of the most intricate and nuanced forms of communication, makes NLP an important field of study in machine learning. Due to the potential of NLP, there has been a significant investment in research and development from businesses like Google, Microsoft, and Facebook \citep{invest}. In the years to come, how we communicate, work, and live will likely be significantly impacted by the continued development of NLP models and techniques.

There has been a lot of interest in using NLP models in all kinds of areas, including politics and education. NLP models can (among other things) be used to spot political leaning, forecast election results, and measure public opinion by examining political speeches, social media posts, and news articles. \citet{sharma2016prediction} for example use sentiment analysis on Hindi Twitter in order to predict Indian elections. Recurrent Neural Networks (RNNs) can be used to detect the political position expressed in a sentence \citep{iyyer2014political}. Bradley Hayes trained a Twitter bot on speeches of Trump which is able to build tweets that sound like they were written by Trump \citep{trump_bot} and \citet{hartmann2023political} uncovers that the language model ChatGPT \citep{chatgpt} has a pro-environmental, left-libertarian orientation, acknowledging that no model can be truly neutral.

These are just some examples of how NLP models can be used in the area of politics. While some of them, like the Trump-bot, are purely entertaining, others aim to solve problems like predicting an election or uncovering biases. Another use case is to use NLP techniques in order to aid human decision-making in regards to politics. Deciding which party to vote for is often not an easy decision. In an increasingly complex world, the opinions and views of each party are also more difficult to grasp and understand. Existing decision aids like the Wahl-O-Mat \citep{wahlomat} use predefined statements to compare the parties' views. Recent advances, however, suggest that automated interfaces based on large-scale language models could be used to create decision aids that are more human-like and effective.

A model that analyzes user-generated statements and forecasts whether each of the parties will agree with the statements is one way to accomplish this goal. Users of this model are able to gain insight into the positions and strategies of each party on a specific issue chosen by them, which enables them to make well-informed decisions on subjects that are relevant to them. Such a tool needs an advanced NLP model that can correctly predict party positions based on a relatively short input sentence from the user. To give more context to the model, it might be useful to also feed it relevant passages from the party manifestos.

This thesis extends \citet{witte_2022}, where a model was fitted with the same goal. But, unlike in this thesis, they did not use the party manifestos as additional context. The aim of this thesis is to investigate whether party stance prediction can be improved by utilizing the information contained in party manifestos. The investigation is structured in three parts: (a) the exploration of several semantic search methods to find relevant passages in the manifestos, (b) the examination of optimal ways to communicate this additional information to the model (input pattern design), and (c) the comparison of performance between two big language models, ELECTRA \citep{clark2020electra} and BERT \citep{devlin2018bert}. By conducting this investigation, the thesis seeks to determine which approach is most effective for enhancing party stance prediction.

This work is structured in the following way: Chapter \ref{statements} introduces the problem setting and the data in detail and provides some relevant background information. In Chapter \ref{methods} all the models and methods used are explained. There will be a general introduction to transformers and a brief overview of the most important NLP models of the last few years. The different semantic search techniques later used are described, and the basics and different approaches to input pattern design are introduced. Chapter \ref{experiments} provides details on the experiments that were conducted, while in Chapter \ref{results} the results are described and analyzed. These are further discussed in Chapter \ref{discussion}. Chapter \ref{discussion} also gives an outlook on further research by discussing the limitations and possible new directions. Chapter \ref{conclusion} draws the final conclusions of this thesis.